{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joseph Gross - Element Classification (multi-label) from LIBS data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all unique filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5419"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "all_filenames = []\n",
    "unique_filenames = []\n",
    "\n",
    "# loops through all the filenames and adds them to a list\n",
    "for filename in Path(\"Training Data\").glob('**/*.txt'):\n",
    "    if \"ASCII\" not in filename.name:\n",
    "        all_filenames.append(\"Training Data/\" + filename.name)\n",
    "    # unique_filenames.append(filename.name[:25])\n",
    "\n",
    "# returns a list of unique filenames to be used next \n",
    "#set(unique_filenames)\n",
    "\n",
    "len(all_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract element from one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_element(filename):\n",
    "    all_element_lists = []\n",
    "    all_element_names = [\"Copper\", \"Iron\", \"Nickel\", \"Tin\", \"Tungsten\", \"Zinc\"]\n",
    "    \n",
    "    # <element>_strings is a list of strings that if found in the filename label that file as a certain element\n",
    "    copper_strings = [\"Cu(NO3)2\", \"Copper\"]\n",
    "    all_element_lists.append(copper_strings)\n",
    "    \n",
    "    iron_strings = [\"Fe(NO3)3\", \"UnknownNail\", \"Iron\"]\n",
    "    all_element_lists.append(iron_strings)\n",
    "    \n",
    "    nickel_strings = [\"Ni(NO3)2\", \"NiCl2\", \"Nickel\"]\n",
    "    all_element_lists.append(nickel_strings)\n",
    "    \n",
    "    tin_strings = [\"SnStandard\", \"Tin\", \"Sn\"]\n",
    "    all_element_lists.append(tin_strings)\n",
    "    \n",
    "    tungsten_strings = [\"WStandard\", \"Tungsten\"]\n",
    "    all_element_lists.append(tungsten_strings)\n",
    "    \n",
    "    zinc_strings = [\"Zn(NO3)2\", \"Zinc\", \"Zn\"]\n",
    "    all_element_lists.append(zinc_strings)\n",
    "    \n",
    "    # For each list of strings, checks if the filename contains any element in that list and if it\n",
    "    # does then it returns that element\n",
    "    test_method = False\n",
    "    for i in range(len(all_element_names)):\n",
    "        if any([element.lower() in filename.lower() for element in all_element_lists[i]]):\n",
    "            test_method = True\n",
    "            return all_element_names[i]\n",
    "    \n",
    "    # tests if an element is found for every filename\n",
    "    # if not, the filename is printed\n",
    "    if test_method == False:\n",
    "        print(filename)\n",
    "        \n",
    "#for element in sorted(all_filenames):\n",
    "    #print(get_element(element))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data from one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# returns a dataframe with the frequency and intensity of a single file\n",
    "def get_data(filename):\n",
    "    df = pd.read_csv(filename, skiprows=13, sep='\\t', names=['freq', 'intensity'])\n",
    "    df = df.set_index('freq')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time how long it takes to process one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test file name: Training Data/Fe(NO3)3@0.0125M.TitratingCurve.Agarose3%dH2O.NegLispCup.LampEnergy10.LIBS07252019_HRD10591_16-59-03-337.txt\n",
      "\n",
      "[0, 1, 0, 0, 0, 0] -> ['copper', 'iron', 'nickel', 'tin', 'tungsten', 'zinc']\n",
      "\n",
      "         intensity\n",
      "freq              \n",
      "223.165     -20.06\n",
      "223.400     -20.06\n",
      "223.635     -20.06\n",
      "223.869     -30.06\n",
      "224.104     -24.06\n",
      "\n",
      "Max time to process all files: 383 seconds\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "import time\n",
    "start = time.time()\n",
    "# Timer starts\n",
    "\n",
    "\n",
    "test_file = all_filenames[randint(0, len(all_filenames))]\n",
    "\n",
    "all_element_names_test = [\"copper\", \"iron\", \"nickel\", \"tin\", \"tungsten\", \"zinc\"]\n",
    "intensities_test = []\n",
    "result_to_print = []\n",
    "\n",
    "df_test = get_data(test_file)\n",
    "intensities_test.append(df_test)\n",
    "\n",
    "element = get_element(test_file).lower()\n",
    "element_index = all_element_names_test.index(element)\n",
    "for i in range(len(all_element_names_test)):\n",
    "    if i == element_index:\n",
    "        result_to_print.append(1)\n",
    "    else:\n",
    "        result_to_print.append(0)\n",
    "\n",
    "print(\"Test file name:\", test_file)\n",
    "print()\n",
    "print(result_to_print, \"->\", all_element_names_test)\n",
    "print()\n",
    "print(intensities_test[0].head(5))\n",
    "\n",
    "# Time ends\n",
    "end = time.time()\n",
    "process_single_file_time = (end-start)\n",
    "print()\n",
    "print(\"Max time to process all files:\", round(len(all_filenames) * process_single_file_time), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the intensities dataframes will be stored in this list before being concatenated into one\n",
    "intensities = []\n",
    "all_element_labels = []\n",
    "\n",
    "\n",
    "# <element>_labels is list of binary values (0/1) that will be used as the \"test\" (label) values for\n",
    "# the training of the algorithms. Each list will be used to train a binary classifier\n",
    "copper_labels = []\n",
    "all_element_labels.append(copper_labels)\n",
    "\n",
    "iron_labels = []\n",
    "all_element_labels.append(iron_labels)\n",
    "\n",
    "nickel_labels = []\n",
    "all_element_labels.append(nickel_labels)\n",
    "\n",
    "tin_labels = []\n",
    "all_element_labels.append(tin_labels)\n",
    "\n",
    "tungsten_labels = []\n",
    "all_element_labels.append(tungsten_labels)\n",
    "\n",
    "zinc_labels = []\n",
    "all_element_labels.append(zinc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_element_names = [\"copper\", \"iron\", \"nickel\", \"tin\", \"tungsten\", \"zinc\"]\n",
    "\n",
    "# loops through every file and processes the information needed\n",
    "for file in all_filenames:\n",
    "    # collects the intensity and frequency data and appends it to the intensities list\n",
    "    df = get_data(file)\n",
    "    if df.index[-2] != 672.689:\n",
    "        print(\"--\", file)\n",
    "    intensities.append(df['intensity'])\n",
    "    \n",
    "    # identifies the element for each file and the index in the above element list\n",
    "    # a binary value (0/1) is then added to each labels list depending on what that element is\n",
    "    # a 1 will be added to the element list for the element identified and a 0 to the rest of the lists\n",
    "    element = get_element(file).lower()\n",
    "    element_index = all_element_names.index(element)\n",
    "    for i in range(len(all_element_labels)):\n",
    "        if i == element_index:\n",
    "            all_element_labels[i].append(1)\n",
    "        else:\n",
    "            all_element_labels[i].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the intensities are concatenated to create a master dataframe will all the data\n",
    "# all the labels are stored in a master list of lists (each interior list will be used\n",
    "# to train a new binary classifier)\n",
    "for i in range(len(intensities)):\n",
    "    df = intensities[i]\n",
    "    if 672.689 == df.index[-2]:\n",
    "        continue\n",
    "    else:\n",
    "        print(all_filenames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5419, 2048) 5419 5419 5419 5419 5419 5419\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>freq</th>\n",
       "      <th>223.165</th>\n",
       "      <th>223.4</th>\n",
       "      <th>223.635</th>\n",
       "      <th>223.86900000000003</th>\n",
       "      <th>224.104</th>\n",
       "      <th>224.338</th>\n",
       "      <th>224.57299999999998</th>\n",
       "      <th>224.808</th>\n",
       "      <th>225.042</th>\n",
       "      <th>225.27700000000002</th>\n",
       "      <th>...</th>\n",
       "      <th>671.07</th>\n",
       "      <th>671.2719999999999</th>\n",
       "      <th>671.475</th>\n",
       "      <th>671.677</th>\n",
       "      <th>671.88</th>\n",
       "      <th>672.082</th>\n",
       "      <th>672.284</th>\n",
       "      <th>672.487</th>\n",
       "      <th>672.689</th>\n",
       "      <th>672.8919999999999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intensity</th>\n",
       "      <td>-21.75</td>\n",
       "      <td>-21.75</td>\n",
       "      <td>-21.75</td>\n",
       "      <td>-17.75</td>\n",
       "      <td>-17.75</td>\n",
       "      <td>-8.75</td>\n",
       "      <td>-6.75</td>\n",
       "      <td>-14.75</td>\n",
       "      <td>9.25</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>74.25</td>\n",
       "      <td>93.25</td>\n",
       "      <td>88.25</td>\n",
       "      <td>76.25</td>\n",
       "      <td>71.25</td>\n",
       "      <td>80.25</td>\n",
       "      <td>75.25</td>\n",
       "      <td>91.25</td>\n",
       "      <td>98.25</td>\n",
       "      <td>90.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intensity</th>\n",
       "      <td>-15.31</td>\n",
       "      <td>-15.31</td>\n",
       "      <td>-15.31</td>\n",
       "      <td>-17.31</td>\n",
       "      <td>-11.31</td>\n",
       "      <td>-6.31</td>\n",
       "      <td>-3.31</td>\n",
       "      <td>-15.31</td>\n",
       "      <td>-16.31</td>\n",
       "      <td>8.69</td>\n",
       "      <td>...</td>\n",
       "      <td>83.69</td>\n",
       "      <td>84.69</td>\n",
       "      <td>88.69</td>\n",
       "      <td>73.69</td>\n",
       "      <td>66.69</td>\n",
       "      <td>84.69</td>\n",
       "      <td>73.69</td>\n",
       "      <td>86.69</td>\n",
       "      <td>83.69</td>\n",
       "      <td>73.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intensity</th>\n",
       "      <td>-24.06</td>\n",
       "      <td>-24.06</td>\n",
       "      <td>-24.06</td>\n",
       "      <td>-25.06</td>\n",
       "      <td>-24.06</td>\n",
       "      <td>-13.06</td>\n",
       "      <td>-12.06</td>\n",
       "      <td>-14.06</td>\n",
       "      <td>-12.06</td>\n",
       "      <td>2.94</td>\n",
       "      <td>...</td>\n",
       "      <td>74.94</td>\n",
       "      <td>63.94</td>\n",
       "      <td>79.94</td>\n",
       "      <td>79.94</td>\n",
       "      <td>78.94</td>\n",
       "      <td>88.94</td>\n",
       "      <td>84.94</td>\n",
       "      <td>90.94</td>\n",
       "      <td>80.94</td>\n",
       "      <td>58.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intensity</th>\n",
       "      <td>-12.00</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>-11.00</td>\n",
       "      <td>-6.00</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>-16.00</td>\n",
       "      <td>-15.00</td>\n",
       "      <td>-6.00</td>\n",
       "      <td>...</td>\n",
       "      <td>93.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>87.00</td>\n",
       "      <td>78.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>84.00</td>\n",
       "      <td>85.00</td>\n",
       "      <td>89.00</td>\n",
       "      <td>85.00</td>\n",
       "      <td>88.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intensity</th>\n",
       "      <td>-10.50</td>\n",
       "      <td>-10.50</td>\n",
       "      <td>-10.50</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>-24.50</td>\n",
       "      <td>-25.50</td>\n",
       "      <td>-13.50</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>-9.50</td>\n",
       "      <td>-4.50</td>\n",
       "      <td>...</td>\n",
       "      <td>84.50</td>\n",
       "      <td>94.50</td>\n",
       "      <td>89.50</td>\n",
       "      <td>81.50</td>\n",
       "      <td>78.50</td>\n",
       "      <td>98.50</td>\n",
       "      <td>74.50</td>\n",
       "      <td>79.50</td>\n",
       "      <td>74.50</td>\n",
       "      <td>85.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "freq       223.165  223.400  223.635  223.869  224.104  224.338  224.573  \\\n",
       "intensity   -21.75   -21.75   -21.75   -17.75   -17.75    -8.75    -6.75   \n",
       "intensity   -15.31   -15.31   -15.31   -17.31   -11.31    -6.31    -3.31   \n",
       "intensity   -24.06   -24.06   -24.06   -25.06   -24.06   -13.06   -12.06   \n",
       "intensity   -12.00   -12.00   -12.00   -11.00    -6.00   -20.00    -5.00   \n",
       "intensity   -10.50   -10.50   -10.50    -3.50   -24.50   -25.50   -13.50   \n",
       "\n",
       "freq       224.808  225.042  225.277   ...     671.070  671.272  671.475  \\\n",
       "intensity   -14.75     9.25    -0.75   ...       74.25    93.25    88.25   \n",
       "intensity   -15.31   -16.31     8.69   ...       83.69    84.69    88.69   \n",
       "intensity   -14.06   -12.06     2.94   ...       74.94    63.94    79.94   \n",
       "intensity   -16.00   -15.00    -6.00   ...       93.00    82.00    87.00   \n",
       "intensity    -1.50    -9.50    -4.50   ...       84.50    94.50    89.50   \n",
       "\n",
       "freq       671.677  671.880  672.082  672.284  672.487  672.689  672.892  \n",
       "intensity    76.25    71.25    80.25    75.25    91.25    98.25    90.25  \n",
       "intensity    73.69    66.69    84.69    73.69    86.69    83.69    73.69  \n",
       "intensity    79.94    78.94    88.94    84.94    90.94    80.94    58.94  \n",
       "intensity    78.00    90.00    84.00    85.00    89.00    85.00    88.00  \n",
       "intensity    81.50    78.50    98.50    74.50    79.50    74.50    85.50  \n",
       "\n",
       "[5 rows x 2048 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df = pd.concat(intensities, axis=1).transpose()\n",
    "print(master_df.shape, len(all_element_labels[0]), len(all_element_labels[1]), len(all_element_labels[2]), \n",
    " len(all_element_labels[3]), len(all_element_labels[4]), len(all_element_labels[5]))\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n",
      "1101\n",
      "2434\n",
      "604\n",
      "600\n",
      "429\n"
     ]
    }
   ],
   "source": [
    "for labels in all_element_labels:\n",
    "    print(sum(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Testing, and Scoring Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifiers = [\n",
    "    #KNeighborsClassifier(3),\n",
    "    #SVC(gamma=2, C=1),\n",
    "    #DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    #MLPClassifier(alpha=1, max_iter=100),\n",
    "    #AdaBoostClassifier(),\n",
    "    #GaussianNB(),\n",
    "    #SVC(kernel=\"linear\", C=0.025),\n",
    "    #GradientBoostingClassifier()\n",
    "]\n",
    "\n",
    "classifiers_to_train = [\n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copper:\n",
      "RandomForestClassifier 0.9912389257339317\n",
      "----------------------------\n",
      "Iron:\n",
      "RandomForestClassifier 0.9718598381372372\n",
      "----------------------------\n",
      "Nickel:\n",
      "RandomForestClassifier 0.9612596481025185\n",
      "----------------------------\n",
      "Tin:\n",
      "RandomForestClassifier 0.9995389580451821\n",
      "----------------------------\n",
      "Tungsten:\n",
      "RandomForestClassifier 0.9990779160903642\n",
      "----------------------------\n",
      "Zinc:\n",
      "RandomForestClassifier 0.9967714291917463\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "X = master_df.values\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "score_dict = {}\n",
    "\n",
    "for clf in classifiers:\n",
    "    score_dict[clf.__class__.__name__] = 1\n",
    "\n",
    "trained_models = []\n",
    "# for every element, a seperate binary classifier is trained, tested, and scored\n",
    "# for every element, all the classifiers are trained, tested, and scores based on the labelled values passed (y)\n",
    "# In this cases, the labelled values passed (y) are looped so that all the different binary lists are used once\n",
    "for i in range(len(all_element_labels)):\n",
    "    y = all_element_labels[i]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=0)\n",
    "    print(all_element_names[i].title() + \":\")\n",
    "    clf = classifiers_to_train[i]\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    trained_models.append(clf)\n",
    "    score = np.mean(cross_val_score(clf, X_test, y_test))\n",
    "    name = clf.__class__.__name__\n",
    "    score_dict[clf.__class__.__name__] *= score\n",
    "    print(name, score)\n",
    "    print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying trained model on waterkeepers data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all unique filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_info(filename):\n",
    "    if \"Location1\" in filename:\n",
    "        return 0\n",
    "    if \"Location2\" in filename:\n",
    "        return 1\n",
    "    if \"Location3\" in filename:\n",
    "        return 2\n",
    "    if \"Location4\" in filename:\n",
    "        return 3\n",
    "    if \"Location5\" in filename:\n",
    "        return 4\n",
    "    if \"Location6\" in filename:\n",
    "        return 5\n",
    "    if \"Location7\" in filename:\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1601, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waterkeepers_filenames = []\n",
    "filenames_by_location = []\n",
    "\n",
    "location_1 = []\n",
    "location_2 = []\n",
    "location_3 = []\n",
    "location_4 = []\n",
    "location_5 = []\n",
    "location_6 = []\n",
    "location_7 = []\n",
    "filenames_by_location.append(location_1)\n",
    "filenames_by_location.append(location_2)\n",
    "filenames_by_location.append(location_3)\n",
    "filenames_by_location.append(location_4)\n",
    "filenames_by_location.append(location_5)\n",
    "filenames_by_location.append(location_6)\n",
    "filenames_by_location.append(location_7)\n",
    "\n",
    "location_dict = {0:\"Location1\", 1:\"Location2\", 2:\"Location3\", 3:\"Location4\",\n",
    "                          4:\"Location5\", 5:\"Location6\", 6:\"Location7\"}\n",
    "\n",
    "# loops through all the filenames and adds them to a list\n",
    "for filename in Path(\"WaterKeepers Data\").glob('**/*/*.txt'):\n",
    "    waterkeepers_filenames.append(\"WaterKeepers Data/\" + filename.name)\n",
    "    location_info = get_location_info(filename.name)\n",
    "    filenames_by_location[location_info].append(\"WaterKeepers Data/\" + \n",
    "                                                location_dict[location_info] + \n",
    "                                                \"/\" + filename.name)\n",
    "\n",
    "len(waterkeepers_filenames), len(filenames_by_location )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_keepers_intensities = []\n",
    "\n",
    "location_1_intensities = []\n",
    "location_2_intensities = []\n",
    "location_3_intensities = []\n",
    "location_4_intensities = []\n",
    "location_5_intensities = []\n",
    "location_6_intensities = []\n",
    "location_7_intensities = []\n",
    "\n",
    "water_keepers_intensities.append(location_1_intensities)\n",
    "water_keepers_intensities.append(location_2_intensities)\n",
    "water_keepers_intensities.append(location_3_intensities)\n",
    "water_keepers_intensities.append(location_4_intensities)\n",
    "water_keepers_intensities.append(location_5_intensities)\n",
    "water_keepers_intensities.append(location_6_intensities)\n",
    "water_keepers_intensities.append(location_7_intensities)\n",
    "\n",
    "# loops through every file and processes the information needed\n",
    "for i in range(len(filenames_by_location)):\n",
    "    location = filenames_by_location[i]\n",
    "    for file in location:\n",
    "        # collects the intensity and frequency data and appends it to the intensities list\n",
    "        water_keepers_df = get_data(file)\n",
    "        water_keepers_intensities[i].append(water_keepers_df['intensity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_keepers_df = []\n",
    "\n",
    "#create a list of dataframes for each location (each dataframe has the intesities data)\n",
    "for i in range(len(water_keepers_intensities)):\n",
    "    temp_df = pd.concat(water_keepers_intensities[i], axis=1).transpose()\n",
    "    #print(temp_df.shape)\n",
    "    water_keepers_df.append(temp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify elements in one location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(location_df):\n",
    "    X = location_df.values\n",
    "    X = scaler.transform(X)\n",
    "\n",
    "    location_results = []\n",
    "    for clf in trained_models:\n",
    "        location_results.append(clf.predict(X))\n",
    "\n",
    "    return location_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions from all locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_results = []\n",
    "\n",
    "for location in water_keepers_df:\n",
    "    location_results.append(get_predictions(location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get premutations of numbers 0-5 (index values for accessing predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# get all combinations of index values in order to analyze the prediction results\n",
    "def get_all_combinations(n):\n",
    "    index_list = list(range(0, n))\n",
    "    all_combinations = []\n",
    "    \n",
    "    for i in range(2, n+1):\n",
    "        all_combinations.append(list(combinations(index_list, i)))\n",
    "        \n",
    "    return all_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (1, 2), (1, 3), (1, 4), (1, 5), (2, 3), (2, 4), (2, 5), (3, 4), (3, 5), (4, 5)] 15\n",
      "[(0, 1, 2), (0, 1, 3), (0, 1, 4), (0, 1, 5), (0, 2, 3), (0, 2, 4), (0, 2, 5), (0, 3, 4), (0, 3, 5), (0, 4, 5), (1, 2, 3), (1, 2, 4), (1, 2, 5), (1, 3, 4), (1, 3, 5), (1, 4, 5), (2, 3, 4), (2, 3, 5), (2, 4, 5), (3, 4, 5)] 20\n",
      "[(0, 1, 2, 3), (0, 1, 2, 4), (0, 1, 2, 5), (0, 1, 3, 4), (0, 1, 3, 5), (0, 1, 4, 5), (0, 2, 3, 4), (0, 2, 3, 5), (0, 2, 4, 5), (0, 3, 4, 5), (1, 2, 3, 4), (1, 2, 3, 5), (1, 2, 4, 5), (1, 3, 4, 5), (2, 3, 4, 5)] 15\n",
      "[(0, 1, 2, 3, 4), (0, 1, 2, 3, 5), (0, 1, 2, 4, 5), (0, 1, 3, 4, 5), (0, 2, 3, 4, 5), (1, 2, 3, 4, 5)] 6\n",
      "[(0, 1, 2, 3, 4, 5)] 1\n"
     ]
    }
   ],
   "source": [
    "for element in get_all_combinations(6):\n",
    "    print(element, len(element))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe with data for each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of dataframes (one dataframe per location) \n",
    "# each dataframe containes the prediction results for that location\n",
    "location_results_df = []\n",
    "\n",
    "for location in location_results:\n",
    "    series_list = []\n",
    "    \n",
    "    for element in location:\n",
    "        series_list.append(pd.Series(element))\n",
    "    \n",
    "    location_results_df.append(pd.concat(series_list, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(location_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new column (sum) given a list of other column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_column(combination, df):\n",
    "    sum = 0\n",
    "    for element in combination:\n",
    "        sum += df[element]\n",
    "        \n",
    "    df[combination] = sum\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all new combinations of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_columns(result_df, i):\n",
    "    for combination in get_all_combinations(6):\n",
    "        for element in combination:\n",
    "            result_df = create_column(element, result_df)\n",
    "            \n",
    "    i_to_location = {0:\"Location1\", 1:\"Location2\", 2:\"Location3\", 3:\"Location4\",\n",
    "                    4:\"Location5\", 5:\"Location6\", 6:\"Location7\"}\n",
    "    result_df['Location'] = i_to_location[i]\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new columns for all locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_all_results_df = []\n",
    "for i in range(len(location_results_df)):\n",
    "    location = location_results_df[i]\n",
    "    location_all_results_df.append(create_new_columns(location, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all location data in one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_locations_results_df = pd.concat(location_all_results_df).set_index(\"Location\")\n",
    "\n",
    "final_df = round(all_locations_results_df.groupby(\"Location\").sum() /\n",
    "            all_locations_results_df.groupby(\"Location\").count() * 10000)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "metal_to_index_dict = {\"copper\":0, \"iron\":1, \"nickel\":2, \"tin\":3, \"tungsten\":4, \"zinc\":5}\n",
    "index_to_metal_dict = {0:\"Copper\", 1:\"Iron\", 2:\"Nickel\", 3:\"Tin\", 4:\"Tungsten\", 5:\"Zinc\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percent of total samples containing each metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of total samples containing each metal\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Copper</th>\n",
       "      <th>Iron</th>\n",
       "      <th>Nickel</th>\n",
       "      <th>Tin</th>\n",
       "      <th>Tungsten</th>\n",
       "      <th>Zinc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Location1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Copper  Iron  Nickel  Tin  Tungsten    Zinc\n",
       "Location                                              \n",
       "Location1     0.0   1.5    0.00  0.0       0.0   23.00\n",
       "Location2     0.0   3.5    0.00  0.0       0.0   15.50\n",
       "Location3     0.0   0.0    0.00  0.0       0.0  100.00\n",
       "Location4     0.0   2.5    0.00  0.0       0.0   23.50\n",
       "Location5     0.0   0.0    5.99  0.0       0.0   50.12\n",
       "Location6     0.0  38.0    0.00  0.0       0.0    1.50\n",
       "Location7     0.0   0.0    0.00  0.0       0.0  100.00"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Percent of total samples containing each metal')\n",
    "result_df = final_df[list(range(0,6))].rename(columns=index_to_metal_dict)\n",
    "#result_df[result_df>0]\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of total samples containing each metal\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Copper</th>\n",
       "      <th>Iron</th>\n",
       "      <th>Nickel</th>\n",
       "      <th>Tin</th>\n",
       "      <th>Tungsten</th>\n",
       "      <th>Zinc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Morningside</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RE black pebble beach</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marjory Stoneman Biscayne Nature Center</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matheson Hammock</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Key Biscayne Yacht Club</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia Key RSMAS</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Key Biscayne Beach Club</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Copper  Iron  Nickel  Tin  Tungsten  \\\n",
       "Location                                                                       \n",
       "Morningside                                 0.0   1.5    0.00  0.0       0.0   \n",
       "RE black pebble beach                       0.0   3.5    0.00  0.0       0.0   \n",
       "Marjory Stoneman Biscayne Nature Center     0.0   0.0    0.00  0.0       0.0   \n",
       "Matheson Hammock                            0.0   2.5    0.00  0.0       0.0   \n",
       "Key Biscayne Yacht Club                     0.0   0.0    5.99  0.0       0.0   \n",
       "Virginia Key RSMAS                          0.0  38.0    0.00  0.0       0.0   \n",
       "Key Biscayne Beach Club                     0.0   0.0    0.00  0.0       0.0   \n",
       "\n",
       "                                           Zinc  \n",
       "Location                                         \n",
       "Morningside                               23.00  \n",
       "RE black pebble beach                     15.50  \n",
       "Marjory Stoneman Biscayne Nature Center  100.00  \n",
       "Matheson Hammock                          23.50  \n",
       "Key Biscayne Yacht Club                   50.12  \n",
       "Virginia Key RSMAS                         1.50  \n",
       "Key Biscayne Beach Club                  100.00  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_num_to_name_dict = {\"Location1\": \"Morningside\" , \"Location2\": \"RE black pebble beach\", \n",
    "                             \"Location3\": \"Marjory Stoneman Biscayne Nature Center\",\n",
    "                             \"Location4\": \"Matheson Hammock\", \"Location5\": \"Key Biscayne Yacht Club\",\n",
    "                             \"Location6\": \"Virginia Key RSMAS\", \"Location7\": \"Key Biscayne Beach Club\"}\n",
    "result_df = result_df.reset_index()\n",
    "\n",
    "result_df[\"Location\"] = result_df[\"Location\"].map(location_num_to_name_dict)\n",
    "result_df = result_df.set_index(\"Location\")\n",
    "print('Percent of total samples containing each metal')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random_number = random.randint(0, len(filenames_by_location[0]))\n",
    "\n",
    "data_filename = filenames_by_location[0][random_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = get_data(data_filename).T\n",
    "\n",
    "frequencies = data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = scaler.transform(data_df.values).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_data = data_df.values.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_backend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b5f4a5f3d097>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstrained_layout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregular_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Raw Data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMatplotlibDeprecationWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m     \u001b[0mrcParamsOrig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRcParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m     rcParamsDefault = RcParams([(key, default) for key, (default, converter) in\n\u001b[1;32m   1113\u001b[0m                                 \u001b[0mdefaultParams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    889\u001b[0m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auto_backend_sentinel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m                 \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrcsetup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auto_backend_sentinel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcycler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/colorbar.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layoutbox\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlayoutbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constrained_layout\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconstrained_layout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/_constrained_layout.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLegend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layoutbox\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlayoutbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/legend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBboxTransformTo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBboxTransformFrom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffsetbox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHPacker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVPacker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextArea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDrawingArea\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffsetbox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDraggableOffsetBox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/offsetbox.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBboxImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbbox_artist\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmbbox_artist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martist\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmartist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mallow_rasterization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_bases\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m from matplotlib import (\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mbackend_tools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtextpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtight_bbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     widgets, get_backend, is_interactive, rcParams)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_backend'"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, constrained_layout=True)\n",
    "axs[0].plot(frequencies, regular_data, \"-\")\n",
    "axs[0].set_title('Raw Data')\n",
    "axs[0].set_xlabel('Wavelength (nm)')\n",
    "axs[0].set_ylabel('Intensity')\n",
    "\n",
    "axs[1].plot(frequencies, normalized_data, \"-\")\n",
    "axs[1].set_title('Normalized Data')\n",
    "axs[1].set_xlabel('Wavelength (nm)')\n",
    "axs[1].set_ylabel('Intensity')\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"Normalized vs Regular Data.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WaterKeepers Data/Location1/Location1.07152019.Energy5.Lamp.07192019.3%Agarose_HRD10591_14-33-26-016.txt\n"
     ]
    }
   ],
   "source": [
    "print(data_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
